\section{Introduction}
\label{sec:slds:introduction}

In order to analyze and understand an animal's behavior, or the sequential set of actions that it elicits through its bodily movements over a period of time, we must first have a consistent and reliable way to track those body poses in both time and space. Meeting this objective has been one of the central goals of scientists working at the intersection of neuroscience, ethology, machine learning, and computer vision over the past decade. The result has been an explosion of work that takes in recordings (typically in the form of video data) of behaving animals and outputs a continuous-time representation of the animals' actions in space \cite{toshev_deeppose_2014, tompson_joint_2014, newell_stacked_2016, cao_realtime_2017, mathis_deeplabcut_2018, pereira_fast_2019, batty_behavenet_2019, graving_deepposekit_2019, bohnslav_deepethogram_2021, marshall_continuous_2021, dunn_geometric_2021, lin_characterizing_2022, sun_self-supervised_2022, pereira_sleap_2022, chen_alphatracker_2023}. These representations often take the form of time-series of ``keypoints," or specific points of interest identified on the body, such as the paws, nose, and tail. 

However, obtaining these time-series representations is just the first step in the process of thoroughly describing an animal's behavior. The next step is to take the results of keypoint tracking and use statistical machine learning models to cluster the data into discrete modules, which can then serve as fundamental units for identifying and interpreting more complex and long-lasting sequences of behavior -- much like we understand language by organizing individual letters into longer structures of syllables, words, sentences, and so on. While there are about as many approaches to behavioral clustering as there are to keypoint estimation, one method that rose to early popularity is a latent variable model known as the autoregressive hidden Markov model, or AR-HMM \cite{bryan_autoregressive_2015}. 

In basic design, an AR-HMM is much like the GLM-HMM discussed in Chapter \ref{ch:glmhmm}. However, in this case, the observational data is some representation of the animal's pose positions at each time point, instead of binary choices; the inputs are the postural data from the previous time point (thus the ``autoregressive" nature of the model), instead of task variables; and because the observations are Gaussian rather than Bernoull-distributed, the mapping between the inputs and choices in each state is linear rather than sigmoidal. When applied to behavioral quantification problems, past applications of AR-HMMs have used depth-imagining video data as the model observations, rather than extracted keypoints \cite{wiltschko_mapping_2015, markowitz_striatum_2018, wiltschko_revealing_2020}. This approach is effective in that the pixels from depth cameras are relatively smoothly-varying in time, leading to learned state representations of long duration (relative to the sampling rate) that readily correspond to identifiable, interpretable behaviors. However, a drawback of this method is that the low-resolution of the depth video data limits the precision and detail of discoverable behaviors. To fully characterize the repertoire of animal behavior, it is thus necessary to employ models that directly leverage keypoint data, which captures postural information at higher resolution. 

In this chapter, we address this need by first fitting an AR-HMM to keypoint data -- extracted using SLEAP \cite{pereira_sleap_2022} -- from videos of mice freely exploring a linear track. We identify some crucial shortcomings in the outcome this approach, namely that the state sequences flicker rapidly in a manner much faster than the animal's behavior. This result has also been observed in other recent work \cite{wu_deep_2020, luxem_identifying_2022}. Hypothesizing that this problem is due to noise in the estimates of the keypoint positions (which vary less smoothly across time than the pixels from depth-imaging cameras), we instead employ a switching Linear Dynamical System (sLDS), which is akin to an AR-HMM except that there is an additional layer of continuous latent states between the observations and the discrete states. 
% * describe sLDS (look to keypoint-MoSeq paper
% * describe basic result
% * mention inference is time consuming, approach taken to improve