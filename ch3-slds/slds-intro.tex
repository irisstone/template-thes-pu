\section{Introduction}
\label{sec:slds:introduction}

In order to analyze and understand an animal's behavior, or the sequential set of actions that it elicits through its bodily movements over a period of time, we must first have a consistent and reliable way to track those body poses in both time and space. Meeting this objective has been one of the central goals of scientists working at the intersection of neuroscience, ethology, machine learning, and computer vision over the past decade. The result has been an explosion of work that takes in recordings (typically in the form of video data) of behaving animals and outputs a continuous-time representation of the animals' actions in space \cite{toshev_deeppose_2014, tompson_joint_2014, newell_stacked_2016, cao_realtime_2017, mathis_deeplabcut_2018, pereira_fast_2019, batty_behavenet_2019, graving_deepposekit_2019, bohnslav_deepethogram_2021, marshall_continuous_2021, dunn_geometric_2021, lin_characterizing_2022, sun_self-supervised_2022, pereira_sleap_2022, chen_alphatracker_2023}. These representations often take the form of time-series of ``keypoints," or specific points of interest identified on the body, such as the paws, nose, and tail. 

However, obtaining these time-series representations is just the first step in the process of thoroughly describing an animal's behavior. The next step is to take the results of keypoint tracking and use statistical machine learning models to cluster the data into discrete modules, which can then serve as fundamental units for identifying and interpreting more complex and long-lasting sequences of behavior -- much like we understand language by organizing individual letters into longer structures of syllables, words, sentences, and so on. While there are about as many approaches to behavioral clustering as there are to keypoint estimation, one method that rose to early popularity is a latent variable model known as the autoregressive hidden Markov model, or AR-HMM \cite{bryan_autoregressive_2015}. 

In basic design, an AR-HMM is much like the GLM-HMM discussed in Chapter \ref{ch:glmhmm}. However, in this case, the observational data is some representation of the animal's pose positions at each time point, instead of binary choices; the inputs are the postural data from the previous time point (thus the ``autoregressive" nature of the model), instead of task variables; and because the observations are Gaussian rather than Bernoull-distributed, the mapping between the inputs and choices in each state is linear rather than sigmoidal. When applied to behavioral quantification problems, past applications of AR-HMMs have used depth-imagining video data as the model observations, rather than extracted keypoints \cite{wiltschko_mapping_2015, markowitz_striatum_2018, wiltschko_revealing_2020}. This approach is effective in that the pixels from depth cameras are relatively smoothly-varying in time, leading to learned state representations of long duration (relative to the sampling rate) that readily correspond to identifiable, interpretable behaviors. However, a drawback of this method is that the low-resolution of the depth video data limits the precision and detail of discoverable behaviors. To fully characterize the repertoire of animal behavior, it is thus necessary to employ models that directly leverage keypoint data, which captures postural information at higher resolution. 

In this chapter, we address this need by first fitting an AR-HMM to keypoint data -- extracted using SLEAP \cite{pereira_sleap_2022} -- from videos of mice freely exploring a linear track. We identify some crucial shortcomings in the outcome this approach, namely that the state sequences flicker rapidly in a manner much faster than the animal's behavior. This result has also been observed in other recent work \cite{wu_deep_2020, luxem_identifying_2022}. Hypothesizing that this problem is due to noise in the estimates of the keypoint positions (which vary less smoothly across time than the pixels from depth-imaging cameras), we instead employed a switching Linear Dynamical System (sLDS) model, which is akin to an AR-HMM except that there is an additional layer of continuous latent states between the observations and the discrete states \cite{ackerson_state_1970, chang_state_1978, fox_nonparametric_2008, murphy_machine_2012, linderman_bayesian_2017}. Whereas the observations are the keypoint coordinates themselves, the continuous latents represent denoised keypoints that allow for discrete state inference that is less affected by jitter in the observations. This results in state sequences that correspond much more closely to expected durations of animal behavior \cite{wiltschko_mapping_2015} and readily map on to identifiable actions such as sitting, walking, and rearing. 

Despite the advantages of using an sLDS over an AR-HMM in terms of model performance and interpretability, one major drawback is the computational time required to fit sLDS models; this is largely due to the need to jointly infer the discrete and continuous state trajectories and the move from an exact to an approximate loss function. This time cost is magnified by the fact that inference in both AR-HMMs and sLDS models relies on iterative fitting procedures such as the Expectation Maximization (EM) algorithm \cite{baum_maximization_1970, dempster_maximum_1977, shumway_approach_1982, bishop_pattern_2006, escola_hidden_2011}. EM is not guaranteed to find the optimal solution for a given model fit; Therefore, a typical approach is to fit the model several times and take the best solution as evidence of having found the global optimum. However, the results of each fit are highly dependent on the values at which the system parameters are initialized, and poor initializations can add to the time-inefficiencies of this method. Conversely, smart initializations, in which the starting guess of the system parameters is close to the true ones, can greatly speed up fitting. Here, we attempt to devise a method for obtaining smart initializations for sLDS models by extending existing ideas for the general linear-Gaussian LDS case from spectral learning \cite{martens_learning_2010, anandkumar_tensor_2014, belanger_linear_2015, hazan_learning_2017, hazan_spectral_2018} and subspace identification \cite{ho_editorial_1966, van_overschee_n4sid_1994, viberg_subspace-based_1995, van_overschee_subspace_1996, qin_overview_2006} to be applicable to the discrete state switching regime. 


% However, when applied to keypoint data, MoSeq failed to identify syllables at this
% characteristic ~400ms timescale, instead producing a set of brief syllables (<100 ms)
% together with a small number of aberrantly long syllables that merged multiple
% behaviors; furthermore, the transitions between these syllables aligned poorly to
% changepoints derived from the keypoint data (Fig. 2a-b). These observations are
% consistent with prior work demonstrating that feeding keypoints to MoSeq generates
% behavioral representations that are less informative than those generated by alternative
% clustering methods13,22. 