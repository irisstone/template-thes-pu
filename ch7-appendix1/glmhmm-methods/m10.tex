\subsection{GLM-HMM}
\label{sec:ap1:m10}
\textit{Model architecture}. To incorporate discrete internal states, we used a hidden Markov model (HMM) with a Bernoulli GLM governing the decision-making behavior in each state. The model is defined by a transition matrix and a vector of GLM weights for each state. The transition matrix contains a fixed set of probabilities that govern the probability of changing from a state $z \in \{ 1, \ldots ,K\}$ on trial $t$ to any other state on the next trial. We refer to these as transition probabilities, which can be abbreviated according to: 
\begin{equation}
\label{eq:m6}
    P_{ij} = p\left( {z_{t + 1} = j|z_t = i} \right)
\end{equation}
Each GLM has a unique set of weights wk that maps the external covariates $x_t$ (coded as described in \ref{sec:ap1:m9}) to the probability of the choice $y_t$ for each of the $k$ states. These probabilities can be expressed as a modified version of Eq. \ref{eq:m4}, as given by:
\begin{equation}
\label{eq:m7}
    p\left( {y_t = 1|x_t,\;z_t = j} \right) = \frac{1}{{1 + {{{\mathrm{exp}}}}\left( { - {{{\mathrm{w}}}}_{{{\mathrm{j}}}}^{{{\mathrm{T}}}}{{{\mathrm{x}}}}_{{{\mathrm{t}}}}} \right)}}
\end{equation}
where $w_j$ is the vector of GLM weights for state $j$. Note that in this expression, the choice probability depends on both the external covariates (inputs) and the state via the state-dependent GLM weights \cite{bengio_input_1994,escola_hidden_2011,calhoun_unsupervised_2019}. We refer to these as ‘observation probabilities’, which can be abbreviated according to: 
\begin{equation}
\label{eq:m8}
    \phi _{ij} = p\left( {y_t = j|x_t,\;z_t = i} \right)
\end{equation}
\textit{Fitting}. We fit the GLM–HMM to the data using the expectation–maximization (EM) algorithm \cite{escola_hidden_2011}. The EM algorithm computes the maximum likelihood estimate of the model parameters using an iterative procedure that involves an E-step (expectation), in which the posterior distribution of the latent variables is calculated, followed by an M-step (maximization), in which the values of the model parameters are updated given the posterior distribution of the latents. These steps are repeated until the log-likelihood of the model converges on a local optimum \cite{bishop_pattern_2006}. \\
The log-likelihood (also referred to as the log marginal likelihood) is obtained from the joint probability distribution over the latent states ${{{\mathbf{Z}}}} = z_1, \ldots ,z_T$ and the observations ${{{\mathbf{Y}}}} = y_1, \ldots ,y_T$
 on each trial given the model parameters $\theta$. Marginalizing over the latents, the log-likelihood is computed as the log of the sum over states of the marginal probabilities and is written as:
\begin{equation}
\label{eq:m9}
    \log \left( {p\left( {{{{\mathbf{Y}}}}|{{{\mathbf{X}}}},\theta } \right)} \right) = \log \left( {\mathop {\sum}\limits_{{{\mathbf{Z}}}} {p({{{\mathbf{Y}}}},{{{\mathbf{Z}}}}|{{{\mathbf{X}}}},\theta )} } \right)
\end{equation}
The set of parameters $\theta$ governing the model consists of a transition matrix and the state-dependent GLM weights, which we described above. We initialized the transition matrix by sampling each row from a Dirichlet distribution, with a larger concentration parameter over the entries along the diagonal ($\alpha _{ii} = 5,\;\alpha _{ij} = 1$), reflecting a slight bias toward self-transitions. For the GLM weights, we reasoned that the true values for each state would likely be in approximately the same range as the true values for the one-state (GLM) case. Therefore, we initialized the per-state GLM weights $w_k$ with $k \in \{ 1, \ldots ,K\}$ by first fitting a basic GLM (‘Bernoulli GLM’) to find $w_0$. Then, as we didn’t want the initial weights to be the same in each state, we initialized $w_k = w_0 + {\it{\epsilon }}_k$ where ${\it{\epsilon }}\sim {{{\mathcal{N}}}}(0,0.2)$. \\
The goal of the E-step of the EM algorithm is to compute $p({{{\mathbf{Z}}}}|{{{\mathbf{X}}}},{{{\mathbf{Y}}}},\theta )$, the posterior probability of the latent states given the observations and the model parameters. This can be obtained using a two-stage message passing algorithm known as the forward–backward algorithm \cite{escola_hidden_2011}. The forward pass, sometimes called ‘filtering’, finds the normalized conditional probability $\hat \alpha (z_t)$ for each state $z$ at trial $t$ by iteratively computing the following according to:  
\begin{equation}
\label{eq:m10}
    \begin{array}{c}\hat \alpha (z_t) = p(z_t|y_{1:t},x_{1:t})\\ = \frac{{p(y_t|z_t,x_t)}}{{p(y_t|y_{1:t - 1})}}\mathop {\sum }\limits_{k = 1}^K p\left( {z_{t - 1} = k,\;y_{1:t - 1}{{{\mathrm{|}}}}x_{1:t - 1}} \right)p(z_t|z_{t - 1} = k)\\ = c_t^{ - 1}\phi _{z_{t - 1,\;y_t}}\mathop {\sum }\limits_{k = 1}^K \hat \alpha \left( {z_{t - 1} = k} \right)P_{k,\;z_t}\end{array}
\end{equation}
where ${c_t} = p({y_t}|{y_{1:t - 1}})$ is a scale factor ensuring the probabilities over states sum to 1, which is computed by summing the unnormalized probabilities. We set the prior distribution over states before the first trial, denoted $\hat \alpha (z_0)$, to be the uniform distribution. Note that this is a normalized version of the forward–backward algorithm that avoids underflow errors \cite{bishop_pattern_2006}.  \\
The backward step, also referred to as ‘smoothing’, takes the information from the forward pass and works in the reverse direction, carrying the information about future states backwards in time to further refine the latent state probabilities. Here we find the normalized conditional probability $\hat \beta \left( {z_t} \right)$ for each state $z$ at trial $t$ by iteratively computing the following according to: 
\begin{equation}
\label{eq:m11}
    \begin{array}{c}\hat \beta \left( {z_t} \right) = \frac{{p(y_{t + 1:T}|x_{t + 1:T},z_t)}}{{p(y_{t + 1:T}|y_{1:t})}}\\ = \frac{1}{{p\left( {y_{t + 1}{{{\mathrm{|}}}}y_{1:t}} \right)}}\mathop {\sum }\limits_{k = 1}^K \frac{{p\left( {y_{t + 2:T}{{{\mathrm{|}}}}x_{t + 2:T},z_{t + 1} = k} \right)}}{{p\left( {y_{t + 2:T}{{{\mathrm{|}}}}y_{1:t + 1}} \right)}}p\left( {y_{t + 1}{{{\mathrm{|}}}}z_{t + 1} = k,x_{t + 1}} \right)p\left( {z_{t + 1} = k{{{\mathrm{|}}}}z_t} \right)\\ = c_{t + 1}^{ - 1}\mathop {\sum }\limits_{k = 1}^K \hat \beta \left( {z_{t + 1} = k} \right)\phi _{k,y_{t + 1}}P_{z_t,k}\end{array}
\end{equation}
where $\hat \beta \left( {z_T} \right) = 1$.
From these two conditional probabilities, we can calculate the marginal posterior probabilities of the latent states given by:
\begin{equation}
\label{eq:m12}
    \gamma \left( {z_t} \right) = p\left( {z_t{{{\mathrm{|}}}}X,Y,\theta } \right) = \hat \alpha (z_t)\hat \beta (z_t)
\end{equation}
which was the goal of the E-step. We can also compute the joint posterior distribution of two successive latents, given by:
\begin{equation}
\label{eq:m13}
    \xi (z_t,z_{t + 1}) = \hat \alpha \left( {z_t} \right)\hat \beta \left( {z_{t + 1}} \right)P_{z_t,z_{t + 1}}\phi _{z_{t + 1},y_{t + 1}}
\end{equation}
which will be important for computing updates in the M-step. Because the format of the data included sessions from several different mice over many days, we computed the forward–backward pass separately for each session. This ensured that the learned transition probabilities would not take into account the effect of the last trial of one session on the first trial of the next session. \\\\
The M-step of the EM algorithm takes the newly computed posterior probabilities over the latents and uses them to update the values of the model parameters (Eqs. \ref{eq:m6}–\ref{eq:m8}) by maximizing the expression for $P$ and $w$. Because the transition probabilities are fixed, we can compute their updates using the closed-form solution given by: 
\begin{equation}
\label{eq:m14}
    P_{jk} = \frac{{\mathop {\sum }\nolimits_{t = 2}^T \xi (z_{t,j},\;z_{t + 1,k})}}{{\mathop {\sum }\nolimits_{l = 1}^K \mathop {\sum }\nolimits_{t = 2}^T \xi (z_{t,j},\;z_{t + 1,l})}}
\end{equation}
This closed-form update can be derived by applying the appropriate Lagrange multipliers to the complete-data log-likelihood function \cite{bishop_pattern_2006}. \\\\
Maximization for $w$ involves minimizing the negative of the log-likelihood function, weighted by the marginal posterior probabilities of the latent states, plus a squared penalty term on the model weights. This penalty can be interpreted as the negative log of a Gaussian prior with mean zero and variance 1, which regularizes by penalizing large weight values. The resulting loss function is given by: 
\begin{equation}
\label{eq:m15}
    L(w) = \mathop {\sum}\limits_{t = 1}^T {\mathop {\sum}\limits_{k = 1}^K \gamma } (z_t = k)\log \left( {p\left( {y_t|x_t,z_t = k} \right)} \right) - \frac{1}{2}w_k^Tw_k
\end{equation}
which we optimized using numerical optimization and the L-BFGS-B algorithm as previously described (see \ref{sec:ap1:m9}). \\\\
Both E- and M-steps of the EM algorithm are guaranteed to increase the log-posterior. We alternated E- and M-steps until the difference between the log-posteriors over ten iterations was smaller than a given tolerance (tol $ =1 \times 10^{-3}$). Because the EM algorithm only guarantees that the log-likelihood will converge upon a local optimum \cite{bishop_pattern_2006}, we fit the model 20 times using different initializations of the weights and transition matrix and verified that the top four or more fits all converged on the same solution (meaning that the weights for each fit were the same within a tolerance of $\pm$0.05) to confirm that the algorithm had indeed found the global optimum. After determining the best fit, we computed the posterior standard deviation of the fitted GLM weights (shown as error bars in Fig. 6a,b and Extended Data Fig. 7d–f) by computing the inverse Hessian of the optimized log-posterior using Python’s `autograd' package. \\ \\
\textit{Model selection}.  In Extended Data Fig. 7a, we performed cross-validation on the data from both the indirect and direct pathway inhibition groups, which revealed that three to five latent states were sufficient to reach a plateau in likelihood. To obtain a test set, we selected $\sim$20\% of sessions from the data to hold out from model fitting. Test sessions were chosen by randomly selecting an approximately equal number of sessions from each of the 13 mice in either group. Constraining the held-out data in this way ensured that the cross-validation results were not affected by possible individual differences across mice. We then calculated the log-likelihood of the test data after fitting the model under parameterizations of 1–5 states to the remaining $\sim$80\% of sessions. We express the log-likelihood in bps, defined according to: 
\begin{equation}
\label{eq:m16}
L_{bps} = l \cdot \frac{{\hat L - \hat L_0}}{{T \cdot {{{\mathrm{log}}}}(2)}}
\end{equation}
where $T$(side) is the number of trials in the test set in which the mice turned in that direction. For all cross-validation results presented in the paper, we report the averaged $L_{bps}$ from five different test sets. We followed the same procedure as above in Extended Data Fig. 7c, selecting the optimal number of previous choices using a three-state GLM–HMM under parameterizations of 1–8 previous choices while holding the number of all other external inputs ($\Delta$ cues, laser, bias and previous rewarded choice) constant. In Extended Data Fig. 7b, we simulated data from the inferred parameters (see `Simulating data’) for a two-state GLM–HMM fit to the real data for the indirect pathway inhibition group. We then performed cross-validation as described above on both the full simulated dataset (‘all data’) and for a small subset (`5\% of data’). We chose to simulate from the two-state model to differentiate the simulation from the real data and to demonstrate the results for an arbitrary choice in the true number of states. \\\\
\textit{Testing}. In Fig. 5c, we compared the performance of the GLM–HMM to the GLM by calculating the log-likelihood of the test sets of individual mice. To do so, we held out data and fitted the model across all animals using the same procedure described above. However, we then split the test set by mouse (thus creating 13 different test sets) and calculated the log-likelihood for each individual animal, thus expressing the log-likelihood in units of mouse bits per session (mbps) given by:
\begin{equation}
\label{eq:m17}
L_{mbps} = l \cdot \frac{{\hat L_m - \hat L_{0m}}}{{T_m \cdot {{{\mathrm{log}}}}(2)}}
\end{equation}
Here, $\hat L_m$ is the optimized log-likelihood of the model in question (either the GLM or three-state GLM–HMM) for a single mouse. Similarly, $\hat L_{0m}$ is the optimized log-likelihood under the bias-only Bernoulli GLM and $T_m$ is the total number of trials for that mouse. We then repeated the procedure for five test sets and took the average of the results for each mouse. \\
In Fig. 5d, we evaluated the prediction accuracy of the GLM for each animal by taking the same training and test sets that we used to find the log-likelihoods and using Eq. \ref{meq2} to calculate the probability of turning right on each trial. We then compared this probability to the mouse’s actual choice on that trial, labeling the trial as correct if the model predicted a 50\% or greater probability of turning in the direction of the mouse’s true choice. We then calculated the prediction accuracy for each mouse as the number of correct trials divided by the total number of trials for that mouse. To evaluate the prediction accuracy of the GLM–HMM for each animal, we computed $p(y_t|x_{1:t - 1},y_{1:t - 1})$, or the predictive distribution for trial $t$ of the test set using the observations from trials $1$ to $t - 1$. This arises from averaging over the state probabilities given previous choice data to get a prediction for a particular trial. That is, we ran the forward pass (see ‘Fitting’) to obtain the state probabilities $p(z_t|x_{1:t - 1},y_{1:t - 1})$, computed the initial choice probabilities $p(y_t|x_t,z_t)$ using Eqs. \ref{eq:m7} and \ref{eq:m8}, and then calculated the predictive distribution according to:
\begin{equation}
\label{eq:m18}
p\left( {y_t|x_{1:t - 1},\;y_{1:t - 1}} \right) = \mathop {\sum }\limits_{k = 1}^K p\left( {y_t|x_t,\;z_t = k} \right)p\left( {z_t = k|x_{1:t - 1},\;y_{1:t - 1}} \right)
\end{equation}
We then ran this forward over all the trials in the test set for each mouse. Finally, we computed the prediction accuracy using the same method described for the GLM prediction accuracy. \\\\
\textit{State assignments}. To determine the most likely state on each trial (Figs. 6c–i and 7g,j and Extended Data Figs. 7g,h, 8 and 10 and Supplementary Fig. 4), we assigned each trial to the state with maximum marginal probability given the inputs and choice data, as computed by the forward–backward algorithm given by:
\begin{equation}
\label{eq:m19}
s_t = \arg \mathop {{\max }}\limits_z \left( {p\left( {z_t|{{{\mathbf{X}}}},{{{\mathbf{Y}}}},\theta } \right)} \right)
\end{equation} 
\textit{Simulating data}.
For the analyses in Fig. 6e,f and Extended Data Figs. 7 and 9, we evaluated the ability of the three-state GLM–HMM to predict choices and state transitions that matched the animals’ actual behavior in each state. Regarding the covariates for the simulation, we kept the evidence ($\Delta$ cues) and optogenetic inhibition from the real data but populated the trial history covariates using simulated previous choices. To simulate choices on each trial, we first computed the observation probabilities (Eqs. \ref{eq:m7} and \ref{eq:m7}) using $x_t^\prime$ (the external covariates) and $w_k$ (the learned weights from the model fitted to real data). The state $k$ on each trial was randomly chosen from a distribution given by the learned transition probabilities $P_{z_{t + 1},z_t}$ from the model fitted to real data. We then randomly generated choices $y_t^\prime$ from the distribution of observation probabilities. Repeating this process for each trial to obtain $x_{1:T}^\prime$ and $y_{1:T}^\prime$, we fit the model to the simulated data using the same procedure described previously (see ‘Fitting’) to obtain the posterior probability over states. For Fig. 6e,f and Extended Data Fig. 7, we computed the psychometric curves for each state using these posterior probabilities and the simulated choices (see ‘Psychometric curve fitting’). \\\\
\textit{Model comparisons}. For the two alternative model comparisons with restricted transition probabilities (Fig. 7k–m), we fit the three-state GLM–HMM using the same general procedure as described above. However, in the case where we disallowed transitions during a session (Fig. 7k), we fixed the transition matrix to the identity matrix and only fit the state-dependent GLM weights. In the case where we disallowed transitions in and out of state 2 (Fig. 7l), we derived a constrained M-step that forced the transition probabilities for state 2 to 0. In detail, the constrained M-step involved zeroing out the transition probabilities associated with state 2 and then renormalizing so the rows of the transition matrix summed to 1. Note that the three sessions that appear to still allow transitions in and/or out of state 2 for mice inhibited in the direct pathway of the DMS (Fig. 7l, right) were due to rare cases where the model had high uncertainty about the state, and the most probable state flipped between state 2 and another state at some point during the session. In Fig. 7m, solid curves denote the average log-likelihood for five different test sets. Held-out data for test sets were selected as a random 20\% of sessions, using an approximately equal number of sessions for each mouse.