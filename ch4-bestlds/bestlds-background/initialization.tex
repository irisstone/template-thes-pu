\subsection{Initialization approaches for EM}
\label{sec:bestlds:background:initialization}

Given the impact that the choice of initialization has on EM performance, it's no surprise that there is an extensive body of work on "smart" EM initialization methods for a variety of state-space models, including both LDS models \cite{buesing_spectral_2012, hazan_learning_2017, hazan_spectral_2018} and HMMs \cite{siddiqi_reduced-rank_2010, hsu_spectral_2012, anandkumar_tensor_2014, liu_efficient_2017, mattila_identification_2017}. Often, these techniques rely on a combination of moment-based estimators \cite{martens_learning_2010, buesing_spectral_2012, hsu_spectral_2012, anandkumar_tensor_2014, mattila_identification_2017} and subspace identification methods \cite{ho_editorial_1966, van_overschee_n4sid_1994, viberg_subspace-based_1995, van_overschee_subspace_1996, andersson_subspace_2009, qin_overview_2006}. Despite this work, a significant gap has persisted in that these methods (1) often don't account for input-driven data and (2) do not work for binomial distributions. BestLDS addresses both of these shortcomings. Although there have been several developments for augmented approaches to EM in logistic models using Polya-Gamma latent variables \cite{polson_bayesian_2013, schein_poisson-gamma_2016}, these methods address other inference challenges in binomial-distributed data rather than improvements in the initialization scheme. However, it will be an interesting case for future study whether bestLDS can be combined with these methods to further improve inference for logistic models.